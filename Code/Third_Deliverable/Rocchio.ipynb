{
 "cells": [
  {
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl.query import Q\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch.client import CatClient"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tw):\n",
    "    \"\"\"\n",
    "    Normalizes the weights in t so that they form a unit-length vector\n",
    "    It is assumed that not all weights are 0\n",
    "    :param tw:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mod = np.sqrt(np.sum([x**2 for x in tw.values()]))\n",
    "    return {t: tw[t]/mod for t in tw.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_term_vector(client, index, id):\n",
    "    \"\"\"\n",
    "    Returns the term vector of a document and its statistics a two sorted list of pairs (word, count)\n",
    "    The first one is the frequency of the term in the document, the second one is the number of documents\n",
    "    that contain the term\n",
    "\n",
    "    :param client:\n",
    "    :param index:\n",
    "    :param id:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    termvector = client.termvectors(index=index, id=id, fields=['text'],\n",
    "                                    positions=False, term_statistics=True)\n",
    "\n",
    "    file_td = {}\n",
    "    file_df = {}\n",
    "\n",
    "    if 'text' in termvector['term_vectors']:\n",
    "        for t in termvector['term_vectors']['text']['terms']:\n",
    "            file_td[t] = termvector['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            file_df[t] = termvector['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "    return sorted(file_td.items()), sorted(file_df.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_count(client, index):\n",
    "    \"\"\"\n",
    "    Returns the number of documents in an index\n",
    "\n",
    "    :param client:\n",
    "    :param index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return int(CatClient(client).count(index=[index], format='json')[0]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTFIDF(client, index, file_id):\n",
    "    \"\"\"\n",
    "    Returns the term weights of a document\n",
    "\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the frequency of the term in the document, and the number of documents\n",
    "    # that contain the term\n",
    "    file_tv, file_df = document_term_vector(client, index, file_id)\n",
    "\n",
    "    max_freq = max([f for _, f in file_tv])\n",
    "\n",
    "    dcount = doc_count(client, index)\n",
    "\n",
    "    tfidfw = {}\n",
    "\n",
    "    for (t, w),(_, df) in zip(file_tv, file_df):\n",
    "        tf = w / max_freq\n",
    "        idf = np.log2(dcount/df)\n",
    "        tfidfw[t]= tf*idf\n",
    "\n",
    "    return tfidfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(words_set, index, client, K, R):\n",
    "\n",
    "    s = Search(using=client, index=index)\n",
    "    \n",
    "    query_elements = [k + '^' + str(words_set[k].values[0]) for k in words_set.columns]\n",
    "   \n",
    "\n",
    "    q = Q('query_string',query=query_elements[0]) \n",
    "\n",
    "    for elem in query_elements[1:]:\n",
    "   \n",
    "        q &= Q('query_string',query=elem)\n",
    "\n",
    "    s = s.query(q)\n",
    "    response = s[0:K].execute()\n",
    "    results = pd.DataFrame(index=['Weight'])\n",
    "    for r in response:  # only returns a specific number of results\n",
    "        df = pd.DataFrame(toTFIDF(client, index, r.meta.id), index=['Weight'])\n",
    "        #df = df.div(np.sqrt(df.pow(2).sum(axis=1)), axis=0)\n",
    "        results = results.add(df, fill_value=0)\n",
    "    \n",
    "    results = results.div(K).sort_values(by ='Weight', axis=1, ascending=False)\n",
    "\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          happy      want        be\n",
       "Weight  0.80904  0.491531  0.322259"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>happy</th>\n      <th>want</th>\n      <th>be</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Weight</th>\n      <td>0.80904</td>\n      <td>0.491531</td>\n      <td>0.322259</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "'''Declaration of variables to be used later'''\n",
    "\n",
    "index = 'news'\n",
    "beta = 0.7\n",
    "alpha = 0.3\n",
    "initial_query = input().split(' ')\n",
    "words = pd.DataFrame(index=['Weight'])\n",
    "for elem in initial_query:\n",
    "    if '^' in elem:\n",
    "        words[elem.split('^')[0]] = int(elem.split('^')[1])\n",
    "    else:\n",
    "        words[elem.split('^')[0]] = 1\n",
    "#words = words.div(np.sqrt(words.pow(2).sum(axis=1)), axis=0)\n",
    "k = 60\n",
    "client = Elasticsearch()\n",
    "R = 4\n",
    "nrounds = int(input())\n",
    "for _ in range(nrounds):\n",
    "    Res = search(words, index, client, k, R)*beta\n",
    "    words = words*alpha\n",
    "    words = words.add(Res, fill_value=0).sort_values(by ='Weight', axis=1, ascending=False)\n",
    "    words = words[words.columns[:R]]\n",
    "    words = words.div(np.sqrt(words.pow(2).sum(axis=1)), axis=0)\n",
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\comp.windows.x/0005584\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\rec.sport.hockey/0010699\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\talk.politics.mideast/0017722\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\sci.crypt/0011253\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\rec.sport.hockey/0010775\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\sci.crypt/0011289\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\talk.politics.guns/0016521\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\comp.sys.mac.hardware/0004899\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\soc.religion.christian/0015168\nPATH= C:\\CAIM\\Data\\Dirty\\20_newsgroups\\misc.forsale/0006135\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=client, index=index)\n",
    "q = Q('query_string',query=words.columns[0] + '^' + str(words[words.columns[0]].values[0])) \n",
    "\n",
    "for elem in words.columns[1:]:\n",
    "    q &= Q('query_string',query=elem + '^' + str(words[elem].values[0]))\n",
    "\n",
    "s = s.query(q)\n",
    "response = s.execute()\n",
    "for r in response:  # only returns a specific number of results\n",
    "    print(f'PATH= {r.path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit (conda)",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "f0147c853d052fb7233589d4fd0b86cfbae0e542432001d5878e77688901c03a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.3-final"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}